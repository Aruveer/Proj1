# main.py
import os
import time
import requests
import json
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel

# --- Gemini API Imports ---
from google import genai
from google.genai import types
# --- End Gemini API Imports ---

# Import GitHub Utilities
try:
    from github_utils import create_repo, push_files_to_repo, enable_github_pages, get_user_login, get_github_client
except ImportError:
    # CRITICAL: This will be hit if github_utils.py is missing or has errors.
    print("FATAL ERROR: Could not import github_utils.py. Ensure the file exists and is correct.")
    exit(1)

# --- Configuration & Environment Variables ---
STUDENT_SECRET = os.getenv("STUDENT_SECRET")

# Initialize Gemini client (it automatically finds $env:GEMINI_API_KEY)
try:
    GEMINI_CLIENT = genai.Client()
    # Use a robust model for code generation
    GEMINI_MODEL = "gemini-2.5-pro" # Excellent for complex code tasks
except Exception as e:
    print(f"Warning: Gemini client could not be initialized. LLM calls will fail. Error: {e}")
    GEMINI_CLIENT = None

# --- Pydantic Data Model (Unchanged) ---
class TaskAttachment(BaseModel):
    name: str
    url: str

class TaskRequest(BaseModel):
    email: str
    secret: str
    task: str
    round: int
    nonce: str
    brief: str
    checks: list[str]
    evaluation_url: str
    attachments: list[TaskAttachment] = []

# --- Simple Persistence (In-memory for this example) ---
PERSISTENT_STORAGE = {}

# --- Utility Functions ---

def validate_secret(secret: str) -> bool:
    """Validates the student-provided secret against the environment variable."""
    return secret == os.getenv("STUDENT_SECRET") # Use os.getenv directly for safety

def llm_generate_code(data: TaskRequest, existing_files: dict = None) -> dict:
    """
    Uses the Gemini API to generate the application files.
    """
    if not GEMINI_CLIENT:
        print("‚ùå Gemini client not initialized. Returning minimal files.")
        raise RuntimeError("GEMINI_API_KEY not found or client failed to initialize.")

    print(f"üß† Generating code for Round {data.round} with Gemini API...")
    
    prompt_context = f"TASK BRIEF: {data.brief}\nEVALUATION CHECKS: {', '.join(data.checks)}\n"
    
    if data.attachments:
        prompt_context += f"ATTACHMENTS PROVIDED: {len(data.attachments)} files. You must instruct the app to use them.\n"
        
    if existing_files:
        prompt_context += "\n\nEXISTING CODE TO REVISE:\n"
        # Provide existing code for context during revision
        for name, content in existing_files.items():
            if name in ['index.html', 'script.js', 'style.css']:
                prompt_context += f"--- {name} ---\n{content[:500]}...\n\n"

    system_prompt = (
        "You are an expert web developer and code generator. Your output MUST be a single JSON object. "
        "The keys must be filenames (e.g., 'index.html', 'script.js'). The values must be the full file content. "
        "For Round 1, include 'LICENSE' (MIT) and a comprehensive 'README.md'. For Round 2, only include files you modify or create."
        "The output must be pure JSON, with no markdown code blocks around it. Ensure the JSON is valid and complete."
    )
    
    try:
        response = GEMINI_CLIENT.models.generate_content(
            model=GEMINI_MODEL,
            contents=[
                # Pass the text directly as a string in the contents list
                prompt_context
            ],
            config=types.GenerateContentConfig(
                system_instruction=system_prompt,
                response_mime_type="application/json",
                temperature=0.7
            )
        )
       

        # The response.text is the raw JSON string
        raw_content = response.text
        generated_files = json.loads(raw_content)

        # Ensure LICENSE/README are present for Round 1
        if data.round == 1:
            if 'LICENSE' not in generated_files:
                 generated_files['LICENSE'] = "The MIT License (MIT)\n(Generated by Gemini)"
            if 'README.md' not in generated_files:
                 generated_files['README.md'] = f"# {data.task}\nThis app was generated by Gemini."

        return generated_files

    except Exception as e:
        print(f"Error during LLM code generation: {e}")
        raise RuntimeError(f"LLM code generation failed: {e}")


# def notify_evaluation_api(data: TaskRequest, repo_url: str, commit_sha: str, pages_url: str):
#     """POSTs the required metadata to the evaluation URL with the 1, 2, 4, 8s retry mechanism."""
#     payload = {
#         "email": data.email,
#         "task": data.task,
#         "round": data.round,
#         "nonce": data.nonce,
#         "repo_url": repo_url,
#         "commit_sha": commit_sha,
#         "pages_url": pages_url
#     }
    
#     print(f"üì§ Notifying evaluation API: {data.evaluation_url}")
    
#     delay = 1
#     for attempt in range(4): # 1, 2, 4, 8 second delays
#         try:
#             response = requests.post(data.evaluation_url, json=payload, timeout=10)
#             if response.status_code == 200:
#                 print("‚úÖ Evaluation API notified successfully (HTTP 200).")
#                 return
#             else:
#                 print(f"‚ö†Ô∏è API returned HTTP {response.status_code}. Retrying in {delay}s...")
#         except requests.exceptions.RequestException as e:
#             print(f"‚ùå Network error while notifying API: {e}. Retrying in {delay}s...")
        
#         time.sleep(delay)
#         delay *= 2
    
#     raise RuntimeError("Evaluation API notification failed after multiple retries.")

# main.py - RESTORED notify_evaluation_api function

def notify_evaluation_api(data: TaskRequest, repo_url: str, commit_sha: str, pages_url: str):
    """POSTs the required metadata to the evaluation URL with the 1, 2, 4, 8s retry mechanism."""
    
    # 1. Define the payload structure (THIS WAS MISSING/IMPLICITLY REMOVED)
    payload = {
        "email": data.email,
        "task": data.task,
        "round": data.round,
        "nonce": data.nonce,
        "repo_url": repo_url,
        "commit_sha": commit_sha,
        "pages_url": pages_url
    }
    
    print(f"üì§ Notifying evaluation API: {data.evaluation_url}")
    
    delay = 1
    # Note: The retry loop will attempt 4 times total (1s, 2s, 4s, 8s delay before next attempt)
    for attempt in range(4): 
        try:
            # Send POST request with the required long timeout (610 seconds)
            response = requests.post(data.evaluation_url, json=payload, timeout=610) 
            
            if response.status_code == 200:
                print("‚úÖ Evaluation API notified successfully (HTTP 200).")
                return
            else:
                print(f"‚ö†Ô∏è API returned HTTP {response.status_code}. Retrying in {delay}s...")
        
        except requests.exceptions.RequestException as e:
            # Log the network error (e.g., DNS failure, connection refused, or timeout)
            print(f"‚ùå Network error while notifying API: {e}. Retrying in {delay}s...")
        
        # Wait before the next attempt
        time.sleep(delay)
        delay *= 2
    
    # If the loop completes without returning, raise a final failure error
    raise RuntimeError("Evaluation API notification failed after multiple retries.")

# --- Round Logic (Unchanged) ---

def round1(data: TaskRequest):
    """Handles the initial build, deploy, and notification."""
    repo_name = f"{data.task}-{data.nonce}"
    
    files = llm_generate_code(data)

    repo = create_repo(repo_name, description=data.brief)
    commit_sha = push_files_to_repo(repo, files, "Round 1: Initial LLM build")

    pages_url = enable_github_pages(repo)
    repo_url = repo.html_url

    PERSISTENT_STORAGE[data.nonce] = {
        "repo_url": repo_url,
        "repo_name": repo_name,
        "last_sha": commit_sha,
        "pages_url": pages_url,
    }

    notify_evaluation_api(data, repo_url, commit_sha, pages_url)
    
def round2(data: TaskRequest):
    """Handles the revision, update, and notification."""
    if data.nonce not in PERSISTENT_STORAGE:
        raise HTTPException(status_code=404, detail=f"Repo context not found for nonce: {data.nonce}. Round 1 must complete first.")

    repo_context = PERSISTENT_STORAGE[data.nonce]
    repo_name = repo_context['repo_name']
    
    g = get_github_client()
    repo = g.get_user().get_repo(repo_name)
    
    existing_files = {}
    for filename in ['index.html', 'script.js', 'style.css']:
        try:
            content = repo.get_contents(filename).decoded_content.decode('utf-8')
            existing_files[filename] = content
        except Exception:
            pass 

    files = llm_generate_code(data, existing_files)

    commit_sha = push_files_to_repo(repo, files, "Round 2: LLM revision based on new brief")

    repo_context['last_sha'] = commit_sha
    
    notify_evaluation_api(data, repo_context['repo_url'], commit_sha, repo_context['pages_url'])

# --- FastAPI Application (Unchanged) ---

app = FastAPI()

@app.post("/handle_task")
async def handle_task(data_dict: dict):
    if not validate_secret(data_dict.get("secret", "")):
        raise HTTPException(status_code=401, detail="Invalid secret provided.")
    
    try:
        data = TaskRequest(**data_dict)
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Invalid task payload structure: {e}")

    try:
        print(f"\n--- Starting Task: {data.task} (Round {data.round}) ---")
        
        if data.round == 1:
            round1(data)
        elif data.round == 2:
            round2(data)
        else:
            raise HTTPException(status_code=400, detail="Invalid round index.")

        print(f"--- Task {data.round} Completed Successfully ---")
        return {"status": "success", "message": f"Task Round {data.round} processed and deployed."}
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"CRITICAL ERROR during task processing: {e}")
        raise HTTPException(status_code=500, detail=f"Deployment or API error: {e}")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
